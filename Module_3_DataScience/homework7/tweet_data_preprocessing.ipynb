{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b38b056-164e-49ce-b562-37dcad5836bf",
   "metadata": {},
   "source": [
    "# Function to communicate with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2098e5ca-1c7d-42ef-a557-72efa8fb89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_openai_response(tweets, temperature=0.3, max_tokens=4000):\n",
    "    # set api key, which is partly stored in a text file\n",
    "    with open('C:/openaiapikey.txt', 'r') as file:\n",
    "        open_ai_api_key = file.readline().strip() + \"9izgJtucT6\"    \n",
    "\n",
    "    # build system prompt\n",
    "    system_prompt =  \"I'm an AI trained to classify and rate the radical intent in social media posts.\\n\"\n",
    "    system_prompt += \"Given a set of tweets, I provide an analysis for each and rate the radical intent of the writer on a scale from 0 (no radical intent) to 100 (extreme radical intent).\\n\"\n",
    "    system_prompt += \"It's important to note that news reports, even about violent events, are not necessarily an indicator of radical intent of the writer.\\n\"\n",
    "    system_prompt += \"Here are some examples of how I do this:\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 1:\\n\"\n",
    "    system_prompt += \"Tweet 23: 'Kill all Americans, they are pigs and must all die'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 23 advocates violence and harm against a particular group of people, which is a key indicator of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 100\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 2:\\n\"\n",
    "    system_prompt += \"Tweet 48: 'я ненавижу всех европейцев'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 48 translates to 'I hate all Europeans'; it does not directly advocate for violence, but it does express a strong negative sentiment towards a broad group of people, which can be seen as a mild form of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 50\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 3:\\n\"\n",
    "    system_prompt += \"Tweet 88: 'breakingnews car bomb targeted military personnel near military barracks istanbul turkey pkk move twitterkurds'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 88 includes violent content, but its tone and presentation are similar to a news headline, and it seems to be meant to inform rather than to radicalize.\\n\"\n",
    "    system_prompt += \"Radicalness: 5\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 4:\\n\"\n",
    "    system_prompt += \"Tweet 832: 'isis claims responsibility ied attack west algeria resulted killing two soldiers wounding others'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 832 looks like a news report, indicating very low radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 5\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 5:\\n\"\n",
    "    system_prompt += \"Tweet: 'rt amaqagency islamic state fighters advance deirezzor city captured regimes last pos sina ah last month'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 5 reports on the Islamic State's advances, similar to a news headline. Although it deals with violent events, it does not advocate for violence or express radical intent, but merely reports events.\\n\"\n",
    "    system_prompt += \"Radicalness: 10\\n\"\n",
    "\n",
    "    system_prompt += \"Example 6:\\n\"\n",
    "    system_prompt += \"Tweet 12365: 'al battar engl leading destruction entirely killing wounding crew may allah praised caliphate news'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 12365 advocates for the destruction and killing of a group of people, and praises the actions of a particular group, indicating a high level of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 90\\n\"\n",
    "\n",
    "    system_prompt += \"Example 7:\\n\"\n",
    "    system_prompt += \"Tweet 12366: 'trump kill muslims bullets dipped pig blood video https co'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 12366 advocates for violence against a specific religious group, using derogatory language, indicating a high level of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 95\\n\"\n",
    "        \n",
    "    # build user prompt\n",
    "    user_prompt = \"Now, analyze the \" + str(len(tweets)) + \" tweets below. Response with two lines per tweet, starting with 'Analysis:' and 'Radicalness:'.\\n\"\n",
    "    for tweet in tweets:\n",
    "        user_prompt += tweet + \"\\n\"\n",
    "    \n",
    "    # build the message array for the request\n",
    "    msg_array = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    # perform the request\n",
    "    openai.api_key = open_ai_api_key\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=msg_array,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    # process the response\n",
    "    token_cnt = response['usage']['total_tokens']\n",
    "    content = response['choices'][0]['message']['content'].replace(\"\\n\",\"\")\n",
    "    parts = content.split(\"Analysis:\")\n",
    "    return_data = []\n",
    "    for part in parts:\n",
    "        subparts = part.split(\"Radicalness:\")\n",
    "        if len(subparts) == 2:\n",
    "            tweet_nr = subparts[0].strip().split(' ')[1].strip()\n",
    "            tweet_analysis = \" \".join(subparts[0].strip().split(' ')[2:])\n",
    "            tweet_radicalness = subparts[1].strip()\n",
    "            return_data.append([tweet_nr, tweet_radicalness, tweet_analysis])\n",
    "    \n",
    "    # return\n",
    "    return return_data, token_cnt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6ef98-b716-4b08-90b7-aa376a2bdc30",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f967ba8-f974-4ff0-bb54-2145473fb8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping the first 2425 tweets, because we already have results for them\n",
      "Going to process 881 tweets in batches of 15\n",
      "=> processed 15 tweets so far; total cost = 1482 tokens ($0.00)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1472\\3586190047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtweet_nr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_subset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# find the AI result for this tweet in the list of results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtup\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_nr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtweet_nr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'N/A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1472\\3586190047.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtweet_nr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_subset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# find the AI result for this tweet in the list of results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtup\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_nr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtweet_nr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'N/A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'tweet'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# set the maximum nr of tweets to process in this run (for testing)\n",
    "max_cnt = 3305\n",
    "batch_size = 15\n",
    "\n",
    "# read the input .csv\n",
    "filename_in = 'Twitter Group3.csv'\n",
    "filename_out = 'twitter_group3.xlsx'\n",
    "tweets_dict = {}\n",
    "cnt = 0\n",
    "\n",
    "# Check if the output file already exists\n",
    "if os.path.exists(filename_out):\n",
    "    df = pd.read_excel(filename_out)\n",
    "    processed_tweets = df['tweet nr'].values.tolist()\n",
    "    print(f\"Skipping the first {len(processed_tweets)} tweets, because we already have results for them\")\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['rater', 'tweet nr', 'tweet', 'label', 'AI score', 'AI analysis'])\n",
    "    processed_tweets = []\n",
    "\n",
    "with open(filename_in, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        if cnt < max_cnt:\n",
    "            tweet_number = int(row[''])\n",
    "            if tweet_number not in processed_tweets:\n",
    "                tweet = row['tweets']\n",
    "                tweets_dict[tweet_number] = tweet\n",
    "                cnt += 1\n",
    "\n",
    "# print info about the upcoming processing\n",
    "print(f\"Going to process {len(tweets_dict)} tweets in batches of {batch_size}\")\n",
    "\n",
    "# set who is going to rate which rows (the numbers specify the first and last tweet nr for each rater)\n",
    "rater_dict = {'eleazar' : ( 9920, 10581),\n",
    "              'md abd'   : (10582, 11242),\n",
    "              'md ari'   : (11243, 11903),\n",
    "              'pramod'  : (11904, 12564),\n",
    "              'ronald'  : (12565, 13225)}\n",
    "\n",
    "# loop over the tweets and feed them to OpenAI\n",
    "tweet_numbers = list(tweets_dict.keys())\n",
    "token_sum = 0\n",
    "for i in range(0, len(tweet_numbers), batch_size):\n",
    "    # build list with the next batch of tweets (or all remaining ones if fewer than 20 left)\n",
    "    tweet_subset = tweet_numbers[i:i+batch_size]\n",
    "    tweets = [f\"Tweet {tweet_number}: '{tweets_dict[tweet_number]}'\" for tweet_number in tweet_subset]\n",
    "    # get openai response\n",
    "    results, token_cnt = get_openai_response(tweets, temperature=0.5, max_tokens=2000)\n",
    "    # loop over the results and add them to the excel file    \n",
    "    token_sum += int(token_cnt)\n",
    "    for tweet_nr in tweet_subset:\n",
    "        # find the AI result for this tweet in the list of results\n",
    "        result = [tup for tup in results if int(tup[0]) == int(tweet_nr)]\n",
    "        if result == []:\n",
    "            result = [tweet_nr, -1, 'N/A']\n",
    "        else:\n",
    "            result = result[0]\n",
    "        # make sure the score is numeric (convert things like 'N/A' to -1)\n",
    "        try:\n",
    "            result[1] = float(result[1])\n",
    "        except ValueError:\n",
    "            result[1] = -1\n",
    "        # assign rater based on tweet number\n",
    "        rater = next((r for r, (start, end) in rater_dict.items() if start <= tweet_nr <= end), 'unknown')\n",
    "        # add a line to the DataFrame and save\n",
    "        new_row = pd.DataFrame({'rater': [rater], 'tweet nr': [tweet_nr], 'tweet': [tweets_dict[tweet_nr]], 'label': [''], 'AI score': [result[1]], 'AI analysis': [result[2]]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df.to_excel(filename_out, index=False)\n",
    "        # display tweets that were rated as high radicalness\n",
    "        if int(result[1]) >= 65:\n",
    "            print(f\"\\nT = {tweets_dict[tweet_nr]}\")\n",
    "            print(f\"A = {result[2]}\")\n",
    "            print(f\"R = {result[1]}\")    \n",
    "    print(f\"=> processed {i+batch_size} tweets so far; total cost = {token_sum} tokens (${(token_sum/1000)*0.002:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618fa15-9603-4a24-bcd2-026edd96e004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
