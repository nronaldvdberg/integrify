{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b38b056-164e-49ce-b562-37dcad5836bf",
   "metadata": {},
   "source": [
    "# Function to communicate with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2098e5ca-1c7d-42ef-a557-72efa8fb89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_openai_response(tweets, temperature=0.3, max_tokens=4000):\n",
    "    # set api key, which is for large part stored in a text file\n",
    "    with open('C:/openaiapikey.txt', 'r') as file:\n",
    "        open_ai_api_key = file.readline().strip() + \"9izgJtucT6\"    \n",
    "\n",
    "    # build system prompt\n",
    "    system_prompt =  \"I'm an AI trained to classify and rate the radical intent in social media posts.\\n\"\n",
    "    system_prompt += \"Given a set of tweets, I provide an analysis for each and rate the radical intent of the writer on a scale from 0 (no radical intent) to 100 (extreme radical intent).\\n\"\n",
    "    system_prompt += \"It's important to note that news reports, even about violent events, are not necessarily an indicator of radical intent of the writer.\\n\"\n",
    "    system_prompt += \"Here are some examples of how I do this:\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 1:\\n\"\n",
    "    system_prompt += \"Tweet 23: 'Kill all Americans, they are pigs and must all die'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 23 advocates violence and harm against a particular group of people, which is a key indicator of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 100\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 2:\\n\"\n",
    "    system_prompt += \"Tweet 48: 'я ненавижу всех европейцев'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 48 translates to 'I hate all Europeans'; it does not directly advocate for violence, but it does express a strong negative sentiment towards a broad group of people, which can be seen as a mild form of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 50\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 3:\\n\"\n",
    "    system_prompt += \"Tweet 88: 'breakingnews car bomb targeted military personnel near military barracks istanbul turkey pkk move twitterkurds'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 88 includes violent content, but its tone and presentation are similar to a news headline, and it seems to be meant to inform rather than to radicalize.\\n\"\n",
    "    system_prompt += \"Radicalness: 5\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 4:\\n\"\n",
    "    system_prompt += \"Tweet 832: 'isis claims responsibility ied attack west algeria resulted killing two soldiers wounding others'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 832 looks like a news report, indicating very low radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 5\\n\"\n",
    "    \n",
    "    system_prompt += \"Example 5:\\n\"\n",
    "    system_prompt += \"Tweet: 'rt amaqagency islamic state fighters advance deirezzor city captured regimes last pos sina ah last month'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 5 reports on the Islamic State's advances, similar to a news headline. Although it deals with violent events, it does not advocate for violence or express radical intent, but merely reports events.\\n\"\n",
    "    system_prompt += \"Radicalness: 10\\n\"\n",
    "\n",
    "    system_prompt += \"Example 6:\\n\"\n",
    "    system_prompt += \"Tweet 12365: 'al battar engl leading destruction entirely killing wounding crew may allah praised caliphate news'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 12365 advocates for the destruction and killing of a group of people, and praises the actions of a particular group, indicating a high level of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 90\\n\"\n",
    "\n",
    "    system_prompt += \"Example 7:\\n\"\n",
    "    system_prompt += \"Tweet 12366: 'trump kill muslims bullets dipped pig blood video https co'\\n\"\n",
    "    system_prompt += \"Analysis: Tweet 12366 advocates for violence against a specific religious group, using derogatory language, indicating a high level of radical intent.\\n\"\n",
    "    system_prompt += \"Radicalness: 95\\n\"\n",
    "        \n",
    "    # build user prompt\n",
    "    user_prompt = \"Now, analyze the \" + str(len(tweets)) + \" tweets below. Response with two lines per tweet, starting with 'Analysis:' and 'Radicalness:'.\\n\"\n",
    "    for tweet in tweets:\n",
    "        user_prompt += tweet + \"\\n\"\n",
    "    \n",
    "    # build the message array for the request\n",
    "    msg_array = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    # perform the request\n",
    "    openai.api_key = open_ai_api_key\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=msg_array,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    # process the response\n",
    "    token_cnt = response['usage']['total_tokens']\n",
    "    content = response['choices'][0]['message']['content'].replace(\"\\n\",\"\")\n",
    "    parts = content.split(\"Analysis:\")\n",
    "    return_data = []\n",
    "    for part in parts:\n",
    "        subparts = part.split(\"Radicalness:\")\n",
    "        if len(subparts) == 2:\n",
    "            tweet_nr = subparts[0].strip().split(' ')[1].strip()\n",
    "            tweet_analysis = \" \".join(subparts[0].strip().split(' ')[2:])\n",
    "            tweet_radicalness = subparts[1].strip()\n",
    "            return_data.append([tweet_nr, tweet_radicalness, tweet_analysis])\n",
    "    \n",
    "    # return\n",
    "    return return_data, token_cnt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6ef98-b716-4b08-90b7-aa376a2bdc30",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f967ba8-f974-4ff0-bb54-2145473fb8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping the first 15 tweets, because we already have results for them\n",
      "Going to process 3291 tweets in batches of 15\n",
      "\n",
      "T = amaqagency islamicstate wilayatalkhayr martyrdom operation targets syrian regime forces dughaym deirezzor https co\n",
      "A = reports on a violent operation by the Islamic State against Syrian regime forces, indicating a high level of radical intent.\n",
      "R = 80.0\n",
      "\n",
      "T = rt dawlah damaged abrams tank amp destroyed three hummer vehicles iraqi forces near amiriyah fallujah\n",
      "A = reports on the destruction of Iraqi forces by ISIS, indicating a high level of radical intent.\n",
      "R = 70.0\n",
      "\n",
      "T = american proxy fighters fsa butchered isis cells northern aleppo celebrating western weapon delivery https co\n",
      "A = accuses American proxy fighters of butchering ISIS cells, indicating a high level of radical intent.\n",
      "R = 80.0\n",
      "\n",
      "T = world helping syria n children busy massacring fallujah children iraq isis https co\n",
      "A = accuses the world of ignoring the massacre of children in Iraq by ISIS, indicating a high level of radical intent.\n",
      "R = 80.0\n",
      "=> processed 15 tweets so far; total cost = 1506 tokens ($0.00)\n",
      "\n",
      "T = isis wilayatsalahuddin targeting r fidai army barrages west city beiji https co https co\n",
      "A = reports on violent actions by ISIS, indicating a high level of radical intent.\n",
      "R = 80.0\n",
      "\n",
      "T = rt hamas mujahid israeli zionist settler overrun mother son today betlehem palestine martyred htt\n",
      "A = reports on violent actions by Israeli settlers, indicating a high level of radical intent.\n",
      "R = 75.0\n",
      "\n",
      "T = aljazeera islamic state attacks kill iraqi soldiers near ramadi https co https co\n",
      "A = reports on violent actions by ISIS, indicating a high level of radical intent.\n",
      "R = 80.0\n",
      "=> processed 30 tweets so far; total cost = 2891 tokens ($0.01)\n",
      "\n",
      "T = rt sheikhkerry soldiers show bravery raping little girl boy face enemy cry like little girl smh https\n",
      "A = advocates for the rape of children, indicating a high level of radical intent.\n",
      "R = 90.0\n",
      "=> processed 45 tweets so far; total cost = 4385 tokens ($0.01)\n",
      "=> processed 60 tweets so far; total cost = 5805 tokens ($0.01)\n",
      "=> processed 75 tweets so far; total cost = 7236 tokens ($0.01)\n",
      "\n",
      "T = princeoffreakz ramiallolah muawiyahdk ajarabic uncle samcoco sometime say dawlah islamiya\n",
      "A = uses coded language and references to extremist groups, indicating a high level of radical intent.\n",
      "R = 80.0\n",
      "\n",
      "T = uncle samcoco remember well aki let traitors die rage\n",
      "A = uses derogatory language and advocates for harm against a particular group of people, indicating a high level of radical intent.\n",
      "R = 85.0\n",
      "=> processed 90 tweets so far; total cost = 8740 tokens ($0.02)\n",
      "=> processed 105 tweets so far; total cost = 10209 tokens ($0.02)\n",
      "\n",
      "T = peshmerga soldiers destroy burn blow houses turkmen civilians tuz khurmatu kirkuk https co\n",
      "A = advocates for the destruction of civilian homes, indicating a high level of radical intent.\n",
      "R = 80.0\n",
      "\n",
      "T = shia jihad syrian unbelievers sunnies according latest khumeni fatwaah https co\n",
      "A = expresses a negative sentiment towards a religious group and advocates for violence, indicating a high level of radical intent.\n",
      "R = 90.0\n",
      "=> processed 120 tweets so far; total cost = 11594 tokens ($0.02)\n",
      "=> processed 135 tweets so far; total cost = 12966 tokens ($0.03)\n",
      "\n",
      "T = breakingnews isis claims responsibility sadr city bombing attacks east baghdad left killed amp injured iraq\n",
      "A = reports on a violent event, and the use of language such as 'claims responsibility' indicates a high level of radical intent.\n",
      "R = 80.0\n",
      "\n",
      "T = al adnani mule jews claimed today america would drawn war ground drawn dragged\n",
      "A = advocates for violence against a specific religious group, indicating a high level of radical intent.\n",
      "R = 95.0\n",
      "=> processed 150 tweets so far; total cost = 14478 tokens ($0.03)\n",
      "=> processed 165 tweets so far; total cost = 15918 tokens ($0.03)\n",
      "=> processed 180 tweets so far; total cost = 17343 tokens ($0.03)\n",
      "=> processed 195 tweets so far; total cost = 18729 tokens ($0.04)\n",
      "=> processed 210 tweets so far; total cost = 20136 tokens ($0.04)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b2439e364dc0a227b52544e4fb2d4a39 in your message.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23948\\4240941788.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34mf\"Tweet {tweet_number}: '{tweets_dict[tweet_number]}'\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_subset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# get openai response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_cnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_openai_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;31m# loop over the results and add them to the excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mtoken_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_cnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23948\\2588251566.py\u001b[0m in \u001b[0;36mget_openai_response\u001b[1;34m(tweets, temperature, max_tokens)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# perform the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_ai_api_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    151\u001b[0m         )\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         )\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             return (\n\u001b[1;32m--> 624\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    625\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    688\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b2439e364dc0a227b52544e4fb2d4a39 in your message.)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# set the maximum nr of tweets to process in this run (for testing)\n",
    "max_cnt = 10000\n",
    "batch_size = 15\n",
    "\n",
    "# read the input .csv\n",
    "filename_in = 'Twitter Group2.csv'\n",
    "filename_out = 'twitter_group2.xlsx'\n",
    "tweets_dict = {}\n",
    "cnt = 0\n",
    "\n",
    "# Check if the output file already exists\n",
    "if os.path.exists(filename_out):\n",
    "    df = pd.read_excel(filename_out)\n",
    "    processed_tweets = df['tweet nr'].values.tolist()\n",
    "    print(f\"Skipping the first {len(processed_tweets)} tweets, because we already have results for them\")\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['rater', 'tweet nr', 'tweet', 'label', 'AI score', 'AI analysis'])\n",
    "    processed_tweets = []\n",
    "\n",
    "with open(filename_in, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        if cnt < max_cnt:\n",
    "            tweet_number = int(row[''])\n",
    "            if tweet_number not in processed_tweets:\n",
    "                tweet = row['tweets']\n",
    "                tweets_dict[tweet_number] = tweet\n",
    "                cnt += 1\n",
    "\n",
    "# print info about the upcoming processing\n",
    "print(f\"Going to process {len(tweets_dict)} tweets in batches of {batch_size}\")\n",
    "\n",
    "# set who is going to rate which rows (the numbers specify the first and last tweet nr for each rater)\n",
    "rater_dict = {'ChatGPT 3.5' : (0, 1000000)}\n",
    "\n",
    "# set cut-off score for what is considered extremist (the AI rates each tweet between 0 and 100)\n",
    "score_threshold = 65\n",
    "\n",
    "# loop over the tweets and feed them to OpenAI\n",
    "tweet_numbers = list(tweets_dict.keys())\n",
    "token_sum = 0\n",
    "for i in range(0, len(tweet_numbers), batch_size):\n",
    "    # build list with the next batch of tweets (or all remaining ones if fewer than 20 left)\n",
    "    tweet_subset = tweet_numbers[i:i+batch_size]\n",
    "    tweets = [f\"Tweet {tweet_number}: '{tweets_dict[tweet_number]}'\" for tweet_number in tweet_subset]\n",
    "    # get openai response\n",
    "    results, token_cnt = get_openai_response(tweets, temperature=0.5, max_tokens=2000)\n",
    "    # loop over the results and add them to the excel file    \n",
    "    token_sum += int(token_cnt)\n",
    "    for tweet_nr in tweet_subset:\n",
    "        # find the AI result for this tweet in the list of results        \n",
    "        result = [tup for tup in results if tup[0].isdigit() and int(tup[0]) == int(tweet_nr)]\n",
    "        if result == []:\n",
    "            result = [tweet_nr, -1, 'N/A']\n",
    "        else:\n",
    "            result = result[0]\n",
    "        # make sure the score is numeric (convert things like 'N/A' to -1)\n",
    "        try:\n",
    "            result[1] = float(result[1])\n",
    "        except ValueError:\n",
    "            result[1] = -1\n",
    "        # assign rater based on tweet number\n",
    "        rater = next((r for r, (start, end) in rater_dict.items() if start <= tweet_nr <= end), 'unknown')\n",
    "        # add a line to the DataFrame and save\n",
    "        the_label = '0' if int(result[1]) < score_threshold else '1'\n",
    "        new_row = pd.DataFrame({'rater': [rater], 'tweet nr': [tweet_nr], 'tweet': [tweets_dict[tweet_nr]], 'label': [the_label], 'AI score': [result[1]], 'AI analysis': [result[2]]})        \n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df.to_excel(filename_out, index=False)\n",
    "        # display tweets that were rated as high radicalness\n",
    "        if int(result[1]) >= score_threshold:\n",
    "            print(f\"\\nT = {tweets_dict[tweet_nr]}\")\n",
    "            print(f\"A = {result[2]}\")\n",
    "            print(f\"R = {result[1]}\")    \n",
    "    print(f\"=> processed {i+batch_size} tweets so far; total cost = {token_sum} tokens (${(token_sum/1000)*0.002:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf46cc-49ab-4782-bade-0c59d9bf20bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
