{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d72fcec-b829-47e7-aabe-66586be47b6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6.3 IMDB images\n",
    "\n",
    "3. Suppose we want to build a data set for a Computer vision task that involves gender images. \n",
    "4. Your tasks are the following:\n",
    "   * Collect 10k male/female images from: https://www.imdb.com\n",
    "   * Make sure to render the whole page using selenium and then use BeautifulSoup  to scrape the images\n",
    "   * Create a folder for male/female\n",
    "   * Each image will be named after the person in the picture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef1a04e-dfb1-41dd-b95d-1f4dae5020e2",
   "metadata": {},
   "source": [
    "# Class with scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dbe38b2-ad69-4ab6-a07f-5414ad35d69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "class IMDBScraper():\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        self.image_dict = {}\n",
    "        self.driver = self.create_webdriver()\n",
    "       \n",
    "    def save_dictionary_to_JSON(self):\n",
    "        print(\"Saving dictionary as JSON\")\n",
    "        with open('imdb_images.json', 'w') as json_file:\n",
    "            json.dump(self.image_dict, json_file)\n",
    "    \n",
    "    def create_webdriver(self):\n",
    "        # create a webdriver instance\n",
    "        exe_location = r\"C:\\Webdriver\\geckodriver.exe\"\n",
    "        firefox_binary_location = r\"C:\\Program Files\\Mozilla Firefox\\firefox.exe\"  \n",
    "        options = Options()\n",
    "        options.binary_location = firefox_binary_location\n",
    "        service = Service(executable_path=exe_location)\n",
    "        driver = webdriver.Firefox(service=service, options=options)\n",
    "        return driver\n",
    "    \n",
    "    # download and save an image \n",
    "    def download_image(self, url, gender, filename):\n",
    "        # create directory path for the gender\n",
    "        dir_path = os.path.join(\"./imdb_images\", gender)\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        # create directory if it doesn't exist\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)        \n",
    "        # do nothing if file was already downloaded earlier\n",
    "        if os.path.exists(file_path):\n",
    "            return\n",
    "        # otherwise, download and save the image\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        # write to file\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    \n",
    "    def scrape_images(self, gender, n_images_to_download):\n",
    "        # initialize\n",
    "        n_downloaded = 0\n",
    "        batch_size = 250\n",
    "        batch_nr = 1\n",
    "        self.driver.get(\"https://www.imdb.com/search/name/?gender=\" + gender + \"&count=\" + str(batch_size) + \"&start=1&ref_=rlm\")\n",
    "        while n_downloaded < n_images_to_download:\n",
    "            start_time = time.time()\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            image_elements = soup.select('.lister-item-image img')\n",
    "            for image_element in image_elements:\n",
    "                # get the URL and name of actor/actress\n",
    "                img_url = image_element['src']\n",
    "                lister_item_content = image_element.find_parent('div', class_='lister-item').find('div', class_='lister-item-content')\n",
    "                name = lister_item_content.find('h3', class_='lister-item-header').find('a').text.strip()\n",
    "                # construct file name based on name\n",
    "                filename = name.strip().replace(' ','_').replace('.','_').replace('?','') + \".jpg\"\n",
    "                filename = ''.join(c for c in filename if c.isalnum() or c.isspace() or c in ('.', '_', '-'))\n",
    "                # download and save the image                \n",
    "                self.download_image(img_url, gender, filename)\n",
    "                # update dictionary\n",
    "                self.image_dict[name] = (gender, filename, img_url)                \n",
    "                # are we done?\n",
    "                if n_downloaded >= n_images_to_download:                   \n",
    "                    break\n",
    "            # Print some progress info\n",
    "            n_seconds = time.time() - start_time\n",
    "            print(f\"Batch nr {batch_nr} ({batch_size} images) took {round(n_seconds,1)} seconds; current repo size = {len(self.image_dict)}\")\n",
    "            batch_nr += 1\n",
    "            # Click 'next' button (the &start=... parameter works only for the first 10k images)\n",
    "            button = self.driver.find_element(By.XPATH, '//a[@class=\"lister-page-next next-page\"]')\n",
    "            button.click()            \n",
    "            time.sleep(10)\n",
    "    \n",
    "        # Save the dictionary as a JSON file\n",
    "        self.save_dictionary_to_JSON()\n",
    "\n",
    "    def print_image_dict(self):\n",
    "        for name, (gender, image_file_name, img_url) in self.image_dict.items():\n",
    "            print(f\"Name: {name}\\nGender: {gender}\\nImage File Name: {image_file_name}\\n\")\n",
    "    \n",
    "    def close_driver(self):\n",
    "        self.driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61563eb1-3ec1-4447-8c5f-e63ff7e3f4a5",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c19682a-3657-4aef-8e41-8906ff68d68f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch nr 1 (250 images) took 2.5 seconds; current repo size = 250\n",
      "Batch nr 2 (250 images) took 0.3 seconds; current repo size = 500\n",
      "Batch nr 3 (250 images) took 0.3 seconds; current repo size = 750\n",
      "Batch nr 4 (250 images) took 0.4 seconds; current repo size = 999\n",
      "Batch nr 5 (250 images) took 0.3 seconds; current repo size = 1249\n",
      "Batch nr 6 (250 images) took 0.4 seconds; current repo size = 1499\n",
      "Batch nr 7 (250 images) took 0.3 seconds; current repo size = 1749\n",
      "Batch nr 8 (250 images) took 0.3 seconds; current repo size = 1999\n",
      "Batch nr 9 (250 images) took 0.4 seconds; current repo size = 2249\n",
      "Batch nr 10 (250 images) took 0.3 seconds; current repo size = 2499\n",
      "Batch nr 11 (250 images) took 0.4 seconds; current repo size = 2749\n",
      "Batch nr 12 (250 images) took 0.3 seconds; current repo size = 2999\n",
      "Batch nr 13 (250 images) took 0.3 seconds; current repo size = 3249\n",
      "Batch nr 14 (250 images) took 0.4 seconds; current repo size = 3499\n",
      "Batch nr 15 (250 images) took 0.3 seconds; current repo size = 3749\n",
      "Batch nr 16 (250 images) took 0.4 seconds; current repo size = 3999\n",
      "Batch nr 17 (250 images) took 0.3 seconds; current repo size = 4249\n",
      "Batch nr 18 (250 images) took 0.4 seconds; current repo size = 4499\n",
      "Batch nr 19 (250 images) took 0.3 seconds; current repo size = 4749\n",
      "Batch nr 20 (250 images) took 0.3 seconds; current repo size = 4999\n",
      "Batch nr 21 (250 images) took 0.4 seconds; current repo size = 5249\n",
      "Batch nr 22 (250 images) took 0.3 seconds; current repo size = 5497\n",
      "Batch nr 23 (250 images) took 0.4 seconds; current repo size = 5747\n",
      "Batch nr 24 (250 images) took 0.3 seconds; current repo size = 5996\n",
      "Batch nr 25 (250 images) took 0.3 seconds; current repo size = 6246\n",
      "Batch nr 26 (250 images) took 0.4 seconds; current repo size = 6494\n",
      "Batch nr 27 (250 images) took 0.3 seconds; current repo size = 6744\n",
      "Batch nr 28 (250 images) took 0.4 seconds; current repo size = 6994\n",
      "Batch nr 29 (250 images) took 0.3 seconds; current repo size = 7244\n",
      "Batch nr 30 (250 images) took 0.4 seconds; current repo size = 7494\n",
      "Batch nr 31 (250 images) took 0.3 seconds; current repo size = 7744\n",
      "Batch nr 32 (250 images) took 0.3 seconds; current repo size = 7994\n",
      "Batch nr 33 (250 images) took 0.4 seconds; current repo size = 8244\n",
      "Batch nr 34 (250 images) took 0.3 seconds; current repo size = 8494\n",
      "Batch nr 35 (250 images) took 0.4 seconds; current repo size = 8744\n",
      "Batch nr 36 (250 images) took 0.3 seconds; current repo size = 8994\n",
      "Batch nr 37 (250 images) took 0.3 seconds; current repo size = 9243\n",
      "Batch nr 38 (250 images) took 0.4 seconds; current repo size = 9492\n",
      "Batch nr 39 (250 images) took 0.3 seconds; current repo size = 9741\n",
      "Batch nr 40 (250 images) took 0.4 seconds; current repo size = 9991\n",
      "Batch nr 41 (250 images) took 6.0 seconds; current repo size = 10240\n",
      "Batch nr 42 (250 images) took 5.9 seconds; current repo size = 10489\n",
      "Batch nr 43 (250 images) took 25.9 seconds; current repo size = 10739\n",
      "Batch nr 44 (250 images) took 19.6 seconds; current repo size = 10989\n",
      "Batch nr 45 (250 images) took 7.1 seconds; current repo size = 11239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scraper \u001b[38;5;241m=\u001b[39m IMDBScraper()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfemale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m scraper\u001b[38;5;241m.\u001b[39mscrape_images(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m      5\u001b[0m scraper\u001b[38;5;241m.\u001b[39mclose_driver()\n",
      "Cell \u001b[1;32mIn[26], line 86\u001b[0m, in \u001b[0;36mIMDBScraper.scrape_images\u001b[1;34m(self, gender, n_images_to_download)\u001b[0m\n\u001b[0;32m     84\u001b[0m     button \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//a[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlister-page-next next-page\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     85\u001b[0m     button\u001b[38;5;241m.\u001b[39mclick()            \n\u001b[1;32m---> 86\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Save the dictionary as a JSON file\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dictionary_to_JSON()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "scraper = IMDBScraper()\n",
    "scraper.scrape_images('female', 10000)\n",
    "scraper.scrape_images('male', 10000)\n",
    "scraper.close_driver()\n",
    "\n",
    "#scraper.print_image_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f873ddd-64f3-4ced-bf6e-9f9f4fa2f187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
